# Controle Inteligente de SemÃ¡foros com Q-Learning ğŸš¦

Este projeto implementa e compara dois mÃ©todos de controle de semÃ¡foros urbanos utilizando o simulador **SUMO (Simulation of Urban MObility)**:

- **Controle de Tempo Fixo (CTB)**: SemÃ¡foros seguem tempos prÃ©-definidos, conforme normas do CTB.
- **Controle Inteligente com Q-Learning**: Um agente de aprendizado por reforÃ§o ajusta os semÃ¡foros dinamicamente, priorizando veÃ­culos de emergÃªncia (vclass `emergency` e `authority`).

O objetivo Ã© analisar a eficiÃªncia do Q-Learning em relaÃ§Ã£o ao mÃ©todo tradicional de tempo fixo, visando reduzir congestionamentos e melhorar o fluxo de veÃ­culos.

## ğŸ“‹ SumÃ¡rio

- [Funcionalidades](#-funcionalidades)
- [Metodologia](#-metodologia)
- [Estrutura do RepositÃ³rio](#-estrutura-do-repositÃ³rio)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [InstalaÃ§Ã£o](#-instalaÃ§Ã£o)
- [Uso](#-uso)
- [MÃ©tricas Avaliadas](#-mÃ©tricas-avaliadas)
- [Resultados](#-resultados)
- [Tecnologias Utilizadas](#-tecnologias-utilizadas)
- [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸš€ Funcionalidades

- DetecÃ§Ã£o automÃ¡tica de veÃ­culos prioritÃ¡rios (emergÃªncia e autoridade), garantindo passagem imediata.
- Treinamento de agentes Q-Learning para controle semafÃ³rico dinÃ¢mico baseado em densidade de trÃ¡fego.
- SimulaÃ§Ã£o comparativa entre controle fixo e Q-Learning.
- GeraÃ§Ã£o de relatÃ³rios visuais (HTML e PDF) com grÃ¡ficos comparativos.
- Logs detalhados em CSV para anÃ¡lise de desempenho.
- ConfiguraÃ§Ã£o de cenÃ¡rios personalizados no SUMO.

---

## ğŸ§  Metodologia

### Controle de Tempo Fixo
- Segue ciclos prÃ©-definidos: 15s verde, 2s amarelo, 30s vermelho.
- NÃ£o adapta ao trÃ¡fego em tempo real.

### Q-Learning
- **Estado**: Densidade de veÃ­culos nas vias horizontais e verticais de cada semÃ¡foro.
- **AÃ§Ãµes**: Alternar para verde horizontal ou vertical.
- **Recompensa**: Penaliza tempo de espera e paradas; bonifica fluxo.
- **ParÃ¢metros**: Î±=0.05 (aprendizado), Î³=0.9 (desconto), Îµ=0.9 (exploraÃ§Ã£o inicial).
- Treinamento com 100 episÃ³dios, cada um com atÃ© 5000 passos.

VeÃ­culos prioritÃ¡rios tÃªm prioridade mÃ¡xima, interrompendo ciclos normais.

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
com_densidade_final_qlearning/
â”œâ”€â”€ tempo_fixo.py                    # SimulaÃ§Ã£o com controle de tempo fixo
â”œâ”€â”€ treinamento_Qlearning.py         # Treinamento do agente Q-Learning
â”œâ”€â”€ simulacao_Qlearning.py           # SimulaÃ§Ã£o com modelo Q-Learning treinado
â”œâ”€â”€ comparar_resultados.py           # ComparaÃ§Ã£o de mÃ©tricas e geraÃ§Ã£o de relatÃ³rios
â”œâ”€â”€ requirements.txt                 # DependÃªncias Python
â”œâ”€â”€ README.md                        # Este arquivo
â”œâ”€â”€ mapa_final_sumo.sumocfg              # ConfiguraÃ§Ã£o principal do SUMO
â”œâ”€â”€ mapa_final_sumo.net.xml              # Rede viÃ¡ria
â”œâ”€â”€ mapa_final_sumo.rou.xml              # Rotas de veÃ­culos
â”œâ”€â”€ mapa_final_sumo.netecfg              # ConfiguraÃ§Ã£o adicional da rede
â”œâ”€â”€ edgeData.xml                     # Dados de arestas (saÃ­da SUMO)
â”œâ”€â”€ laneData.xml                     # Dados de faixas (saÃ­da SUMO)
â”œâ”€â”€ tripinfo.xml                     # InformaÃ§Ãµes de viagens (saÃ­da SUMO)
â”œâ”€â”€ output.txt                       # Log de saÃ­da
â”œâ”€â”€ priority_log.csv                 # Log de prioridades
â”œâ”€â”€ __pycache__/                     # Cache Python
â”œâ”€â”€ relatorio/                       # RelatÃ³rios gerados
â”‚   â”œâ”€â”€ relatorio_comparativo_prioritarios.html
â”‚   â”œâ”€â”€ relatorio_comparativo.html
â”‚   â”œâ”€â”€ relatorio_prioritarios_qlearning.html
â”‚   â””â”€â”€ relatorio_prioritarios_tempo_fixo.html
â”œâ”€â”€ resultados_qlearning/            # Resultados Q-Learning
â”‚   â”œâ”€â”€ authority_qlearning.csv
â”‚   â”œâ”€â”€ carros_parados_prioritarios_qlearning.csv
â”‚   â”œâ”€â”€ densidade_prioritarios_qlearning.csv
â”‚   â”œâ”€â”€ densidade_qlearning.csv
â”‚   â”œâ”€â”€ emergency_qlearning.csv
â”‚   â”œâ”€â”€ espera_prioritarios_qlearning.csv
â”‚   â”œâ”€â”€ espera_qlearning.csv
â”‚   â”œâ”€â”€ metricas_qlearning.csv
â”‚   â”œâ”€â”€ paradas_prioritarios_qlearning.csv
â”‚   â”œâ”€â”€ paradas_qlearning.csv
â”‚   â”œâ”€â”€ resultado_qlearning.csv
â”‚   â”œâ”€â”€ traffic_results_fast_reaction.csv
â”‚   â”œâ”€â”€ velocidade_prioritarios_qlearning.csv
â”‚   â””â”€â”€ velocidade_qlearning.csv
â””â”€â”€ resultados_tempo_fixo/           # Resultados Tempo Fixo
    â”œâ”€â”€ authority_tempo_fixo.csv
    â”œâ”€â”€ carros_parados_prioritarios_tempo_fixo.csv
    â”œâ”€â”€ densidade_prioritarios_tempo_fixo.csv
    â”œâ”€â”€ densidade_tempo_fixo.csv
    â”œâ”€â”€ emergency_tempo_fixo.csv
    â”œâ”€â”€ espera_prioritarios_tempo_fixo.csv
    â”œâ”€â”€ espera_tempo_fixo.csv
    â”œâ”€â”€ metricas_tempo_fixo.csv
    â”œâ”€â”€ paradas_prioritarios_tempo_fixo.csv
    â”œâ”€â”€ paradas_tempo_fixo.csv
    â”œâ”€â”€ resultado_tempo_fixo.csv
    â”œâ”€â”€ velocidade_prioritarios_tempo_fixo.csv
    â””â”€â”€ velocidade_tempo_fixo.csv
```

---

## ğŸ“‹ PrÃ©-requisitos

- **Python 3.8+**
- **SUMO (Simulation of Urban MObility)**: Baixe e instale do [site oficial](https://www.eclipse.org/sumo/).
  - Adicione o SUMO ao PATH do sistema.
- **Git** (para clonar o repositÃ³rio)

---

## âš™ï¸ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio
```bash
git clone https://github.com/seu-usuario/controle-semaforos-ql.git
cd controle-semaforos-ql
```

### 2. Instale o SUMO
- Baixe a versÃ£o mais recente do [SUMO](https://www.eclipse.org/sumo/download.php).
- Siga as instruÃ§Ãµes de instalaÃ§Ã£o para seu sistema operacional.
- Verifique se `sumo` e `sumo-gui` estÃ£o no PATH:
  ```bash
  sumo --version
  ```

### 3. Crie um ambiente virtual (recomendado)
```bash
python -m venv venv
venv\Scripts\activate  # Windows
# ou
source venv/bin/activate  # Linux/Mac
```

### 4. Instale as dependÃªncias Python
```bash
pip install -r requirements.txt
```

---

## ğŸš€ Uso

### 1. Treinamento do Agente Q-Learning
Executa o treinamento e salva a tabela Q em `q_table.pkl`:
```bash
python treinamento_Qlearning.py
```

### 2. SimulaÃ§Ã£o com Controle de Tempo Fixo
Executa a simulaÃ§Ã£o com tempos fixos e gera logs:
```bash
python tempo_fixo.py
```

### 3. SimulaÃ§Ã£o com Q-Learning
Carrega o modelo treinado e executa a simulaÃ§Ã£o:
```bash
python simulacao_Qlearning.py
```

### 4. ComparaÃ§Ã£o de Resultados
Gera relatÃ³rios comparativos em HTML e PDF:
```bash
python comparar_resultados.py
```

Os relatÃ³rios serÃ£o salvos na pasta `relatorio/`.

---

## ğŸ“Š MÃ©tricas Avaliadas

- **Tempo MÃ©dio de Espera**: Tempo que veÃ­culos aguardam nos semÃ¡foros.
- **NÃºmero de Paradas**: Total de paradas por veÃ­culo.
- **Velocidade MÃ©dia**: Velocidade mÃ©dia dos veÃ­culos.
- **Densidade de TrÃ¡fego**: NÃºmero de veÃ­culos por unidade de espaÃ§o.
- **MÃ©tricas para PrioritÃ¡rios**: MÃ©tricas especÃ­ficas para veÃ­culos de emergÃªncia e autoridade.

---

## ğŸ“ˆ Resultados

Os resultados mostram que o Q-Learning reduz significativamente o tempo de espera e o nÃºmero de paradas em comparaÃ§Ã£o ao controle fixo, especialmente em cenÃ¡rios de trÃ¡fego variÃ¡vel. VeÃ­culos prioritÃ¡rios tÃªm prioridade garantida em ambos os mÃ©todos.

Exemplos de arquivos de saÃ­da:
- `resultado_tempo_fixo.csv`: MÃ©tricas gerais para tempo fixo.
- `traffic_results_fast_reaction.csv`: Resultados detalhados do Q-Learning.
- `priority_log.csv`: Logs de ativaÃ§Ã£o de prioridade.

Visualize os relatÃ³rios HTML na pasta `relatorio/` para grÃ¡ficos comparativos.

---

## ğŸ›  Tecnologias Utilizadas

- **Python 3**: Linguagem principal.
- **SUMO**: Simulador de trÃ¡fego.
- **Q-Learning**: Algoritmo de aprendizado por reforÃ§o.
- **Pandas**: ManipulaÃ§Ã£o de dados.
- **NumPy**: ComputaÃ§Ãµes numÃ©ricas.
- **Matplotlib**: GeraÃ§Ã£o de grÃ¡ficos.
- **ReportLab**: CriaÃ§Ã£o de PDFs.

---

## ğŸ¤ ContribuiÃ§Ã£o

ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga estes passos:

1. Fork o projeto.
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`).
3. Commit suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`).
4. Push para a branch (`git push origin feature/nova-feature`).
5. Abra um Pull Request.

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

Para dÃºvidas ou sugestÃµes, abra uma issue no GitHub.